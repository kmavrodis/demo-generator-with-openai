{"id": "3f2236de-d10b-461b-9ffe-0f0449bb31e8", "use_case": "Document Information Extraction with Document Intelligence and GPT4", "detailed_description": "### Demo Description: Document Information Extraction with Document Intelligence and GPT-4\n\n#### Main Features of the Demo\n- **Document Upload**: Users can upload documents (PDF, DOCX).\n- **Information Extraction**: Extract key information like names, dates, and addresses using Document Intelligence API.\n- **Text Summarization**: Summarize the extracted information using GPT-4.\n- **Visual Representation**: Display the extracted data and summary in a user-friendly format.\n\n#### User Interface Elements\n- **File Upload Widget**: For uploading documents.\n- **Extract Button**: To start the extraction process.\n- **Text Display Areas**: Sections to show extracted information and generated summaries.\n- **Visual Charts**: Basic charts or tables to represent extracted data (using Plotly).\n\n#### Data Processing Steps\n1. **File Upload**: User uploads a document via the Streamlit file upload widget.\n2. **Data Extraction**: Utilize the Document Intelligence API to extract key information from the uploaded document.\n3. **Text Analysis**: Use GPT-4 to summarize the extracted data.\n4. **Display Results**: Show extracted information and the summary in a structured format.\n5. **Visual Representation**: Optionally, create visual elements (charts or tables) using Plotly to represent the data.\n\n**Engineer Instructions**:\n- Use Streamlit for creating the user interface.\n- Integrate the Document Intelligence API for extracting information.\n- Utilize GPT-4 for summarizing the extracted information.\n- Add visual elements using Plotly and dummy data for initial testing.\n\nThis should create a straightforward yet powerful demo of document information extraction and summarization.", "code": "import os\nimport streamlit as st\nfrom openai import AzureOpenAI\nfrom azure.ai.documentintelligence import DocumentIntelligenceClient\nfrom azure.core.credentials import AzureKeyCredential\nfrom PIL import Image\nimport base64\n\n# Ensure required packages are installed\ntry:\n    import fitz  # PyMuPDF\nexcept ImportError:\n    os.system('pip install PyMuPDF')\n\n# Set up environment variables for API keys and endpoints\nAZURE_WHISPER_KEY = os.getenv(\"AZURE_WHISPER_KEY\")\nAZURE_WHISPER_DEPLOYMENT = os.getenv(\"AZURE_WHISPER_DEPLOYMENT\")\nAZURE_WHISPER_ENDPOINT = os.getenv(\"AZURE_WHISPER_ENDPOINT\")\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nOPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\nOPENAI_ENDPOINT = os.getenv(\"OPENAI_ENDPOINT\")\nDOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\")\nDOCUMENT_INTELLIGENCE_KEY = os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\")\n\n# Initialize the Azure OpenAI client\nopenai_client = AzureOpenAI(\n    api_key=OPENAI_API_KEY,\n    api_version=\"2023-12-01-preview\",\n    azure_endpoint=OPENAI_ENDPOINT\n)\n\n# Initialize the Document Intelligence client\ndocument_intelligence_client = DocumentIntelligenceClient(\n    endpoint=DOCUMENT_INTELLIGENCE_ENDPOINT,\n    credential=AzureKeyCredential(DOCUMENT_INTELLIGENCE_KEY),\n    api_version=\"2023-10-31-preview\"\n)\n\n# Streamlit App Title and Description\nst.title(\"Document Information Extraction with AI\")\nst.write(\"Upload documents and extract key information like names, dates, and addresses. Summarize the extracted information using GPT-4, and visualize the data in tables or charts.\")\n\n# Function to get OCR results from Document Intelligence\ndef get_ocr_results(file_path: str):\n    with open(file_path, \"rb\") as f:\n        poller = document_intelligence_client.begin_analyze_document(\n            \"prebuilt-layout\",\n            analyze_request=f,\n            content_type=\"application/octet-stream\"\n        )\n    return poller.result()\n\n# Function to convert PDF pages to images using PyMuPDF\ndef convert_pdf_to_images(pdf_path):\n    doc = fitz.open(pdf_path)\n    image_files = []\n    for i, page in enumerate(doc):\n        pix = page.get_pixmap()\n        image_path = f\"data/document_analysis/page_{i + 1}.png\"\n        pix.save(image_path)\n        image_files.append(image_path)\n    return image_files\n\n# Function to encode images to base64\ndef encode_image_to_base64(image_path):\n    with open(image_path, \"rb\") as img_file:\n        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n\n# Function to transform markdown to JSON using GPT-4 with images as context\ndef markdown_to_json_with_images(markdown_text: str, images: list) -> str:\n    messages = [\n        {\"role\": \"user\", \"content\": f\"Transform the following markdown into a JSON structure using the provided images for context and validation:\\n\\n{markdown_text}\"}\n    ]\n    \n    for img in images:\n        messages.append({\"role\": \"user\", \"content\": [{\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{encode_image_to_base64(img)}\"}}]})\n    \n    response = openai_client.chat.completions.create(\n        model=OPENAI_DEPLOYMENT_NAME,\n        messages=messages,\n        max_tokens=4096,\n        response_format={\"type\": \"json_object\"}\n    )\n    result = response.choices[0].message.content\n    json_content = result.strip('```json').strip()\n    return json_content\n\n# File upload widget\nuploaded_file = st.file_uploader(\"Upload a PDF or DOCX document\", type=[\"pdf\", \"docx\"])\n\nif uploaded_file is not None:\n    file_path = f\"data/document_analysis/{uploaded_file.name}\"\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    \n    with open(file_path, \"wb\") as f:\n        f.write(uploaded_file.getbuffer())\n\n    if file_path.endswith(\".pdf\"):\n        # Extract information from the document\n        st.write(\"Extracting information from the document...\")\n        ocr_result = get_ocr_results(file_path)\n\n        # Convert PDF pages to images\n        st.write(\"Converting PDF pages to images...\")\n        image_files = convert_pdf_to_images(file_path)\n        \n        # Extract relevant information as markdown\n        extracted_markdown = \"\"\n        for page in ocr_result.pages:\n            for item in page.lines:\n                extracted_markdown += f\"- {item.content}\\n\"\n\n        col1, col2 = st.columns([3, 1])\n\n        with col1:\n            st.write(\"### PDF Preview\")\n            for image in image_files:\n                st.image(image, use_column_width=True)\n\n        with col2:\n            st.write(\"### Extracted Information\")\n            st.text_area(\"Extracted Information\", value=extracted_markdown, height=200)\n\n            # Transform the extracted markdown into JSON using GPT-4 with images for context\n            st.write(\"Transforming the extracted information into JSON using images for validation...\")\n            json_structure = markdown_to_json_with_images(extracted_markdown, image_files)\n            \n            st.write(\"### JSON Structure\")\n            try:\n                st.json(json_structure)\n            except Exception:\n                st.text(json_structure)\n\n    else:\n        st.write(\"Currently, only PDF documents are supported for extraction.\")\nelse:\n    st.write(\"Please upload a PDF or DOCX document to extract and summarize its information.\")"}